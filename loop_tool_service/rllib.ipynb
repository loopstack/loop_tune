{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dejang/anaconda3/envs/compiler_gym/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!pip install compiler_gym 'ray[default,rllib]' &>/dev/null || echo \"Install failed!\"\n",
    "\n",
    "import compiler_gym\n",
    "import ray\n",
    "\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from compiler_gym.wrappers import ConstrainedCommandline, TimeLimit\n",
    "from ray import tune\n",
    "from itertools import islice\n",
    "from compiler_gym.wrappers import CycleOverBenchmarks\n",
    "from compiler_gym.util.registration import register\n",
    "\n",
    "import loop_tool_service\n",
    "\n",
    "from service_py.datasets import loop_tool_dataset\n",
    "from service_py.rewards import flops_loop_nest_reward, flops_reward, runtime_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env() -> compiler_gym.envs.CompilerEnv:\n",
    "    \"\"\"Make the reinforcement learning environment for this experiment.\"\"\"\n",
    "    \n",
    "    env = loop_tool_service.make(\n",
    "        \"loop_tool_env-v0\",\n",
    "        observation_space=\"ir_tensor\",\n",
    "        reward_space=\"flops_loop_nest_tensor\",\n",
    "        # reward_space=\"runtime\",\n",
    "    )\n",
    "\n",
    "    env = TimeLimit(env, max_episode_steps=10)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: NamedDiscrete([up, down, swap_up, swap_down])\n",
      "Observation space: Box([[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], [[256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256.\n",
      "  256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256.\n",
      "  256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256.\n",
      "  256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256. 256.\n",
      "  256. 256. 256. 256.]], (1, 60), float32)\n",
      "Reward space: flops_loop_nest_tensor\n"
     ]
    }
   ],
   "source": [
    "with make_env() as env:\n",
    "    print(\"Action space:\", env.action_space)\n",
    "    print(\"Observation space:\", env.observation_space)\n",
    "    print(\"Reward space:\", env.reward_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of benchmarks for training: 1\n",
      "Number of benchmarks for testing: 1\n"
     ]
    }
   ],
   "source": [
    "with make_env() as env:\n",
    "    # The two datasets we will be using:\n",
    "    lt_dataset = env.datasets[\"loop_tool_simple-v0\"]\n",
    "    # train_benchmarks = list(islice(lt_dataset.benchmarks(), 1))\n",
    "    # test_benchmarks = list(islice(lt_dataset.benchmarks(), 2))\n",
    "    \n",
    "    bench = [\"benchmark://loop_tool_simple-v0/simple\"]\n",
    "            #  \"benchmark://loop_tool_simple-v0/mm128\", \n",
    "            #  \"benchmark://loop_tool_simple-v0/mm\"] \n",
    "\n",
    "    train_benchmarks = bench\n",
    "    test_benchmarks = bench\n",
    "\n",
    "print(\"Number of benchmarks for training:\", len(train_benchmarks))\n",
    "print(\"Number of benchmarks for testing:\", len(test_benchmarks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_env(*args) -> compiler_gym.envs.CompilerEnv:\n",
    "    \"\"\"Make a reinforcement learning environment that cycles over the\n",
    "    set of training benchmarks in use.\n",
    "    \"\"\"\n",
    "    del args  # Unused env_config argument passed by ray\n",
    "    return CycleOverBenchmarks(make_env(), train_benchmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0628 12:45:36.566179 140569554388544 example_service.py:250] CRITICAL - \n",
      "\n",
      "Working_dir = /dev/shm/compiler_gym_dejang/s/0628T124535-535834-ecb5\n",
      "\n",
      "E0628 12:45:36.673875 140569554388544 example_service.py:250] CRITICAL - \n",
      "\n",
      "Working_dir = /dev/shm/compiler_gym_dejang/s/0628T124535-535834-ecb5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      " for n_5625 in 128 : L1  \n",
      "  for k_5587 in 128 : L2  \n",
      "   %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "   %3[m_5586, n_5625] <- add(%2)  \n",
      "  %4[m_5586, n_5625] <- write(%3)  \n",
      "\n",
      "benchmark://loop_tool_simple-v0/simple\n",
      "for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      " for n_5625 in 128 : L1  \n",
      "  for k_5587 in 128 : L2  \n",
      "   %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "   %3[m_5586, n_5625] <- add(%2)  \n",
      "  %4[m_5586, n_5625] <- write(%3)  \n",
      "\n",
      "benchmark://loop_tool_simple-v0/simple\n"
     ]
    }
   ],
   "source": [
    "with make_training_env() as env:\n",
    "    env.reset()\n",
    "    print(env.benchmark)\n",
    "    env.reset()\n",
    "    print(env.benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      " for n_5625 in 128 : L1  \n",
      "  for k_5587 in 128 : L2  \n",
      "   %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "   %3[m_5586, n_5625] <- add(%2)  \n",
      "  %4[m_5586, n_5625] <- write(%3)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0628 12:45:59.961900 139699708487232 example_service.py:250] CRITICAL - \n",
      "\n",
      "Working_dir = /dev/shm/compiler_gym_dejang/s/0628T124558-926091-2897\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.,   0.,   0.,   0., 128.,   0.,   0.,   0.,   0.,   2., 128.,\n",
       "          0.,   0.,   0.,   0.,   1., 128.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = make_training_env()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1.,   0.,   0.,   0., 128.,   0.,   0.,   0.,   0.,   2., 128.,\n",
       "           0.,   0.,   0.,   0.,   1., 128.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.]], dtype=float32),\n",
       " -2134068176.24735,\n",
       " False,\n",
       " {'action_had_no_effect': True, 'new_action_space': False})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init(include_dashboard=False, ignore_reinit_error=True)\n",
    "\n",
    "tune.register_env(\"compiler_gym\", make_training_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from ray import tune\n",
    "from ray.tune import Stopper\n",
    "\n",
    "class TimeStopper(Stopper):\n",
    "    def __init__(self):\n",
    "        self._start = time.time()\n",
    "        self._deadline = 1\n",
    "\n",
    "    def __call__(self, trial_id, result):\n",
    "        return False\n",
    "\n",
    "    def stop_all(self):\n",
    "        return time.time() - self._start > self._deadline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=2264213)\u001b[0m 2022-06-28 12:48:54,326\tINFO trainer.py:2332 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2264213)\u001b[0m 2022-06-28 12:48:54,543\tINFO ppo.py:414 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=2264213)\u001b[0m 2022-06-28 12:48:54,543\tINFO trainer.py:903 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m E0628 12:48:59.955425 140386616428096 example_service.py:250] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0628T124858-923072-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-28 12:49:02 (running for 00:00:12.78)<br>Memory usage on this node: 15.6/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/12 CPUs, 0/0 GPUs, 0.0/10.78 GiB heap, 0.0/5.39 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-28_12-48-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_2f650_00000</td><td>RUNNING </td><td>100.37.253.28:2264213</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=2264213)\u001b[0m 2022-06-28 12:49:02,671\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m E0628 12:49:02.697907 140386616428096 example_service.py:250] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0628T124858-923072-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  2\n",
      "Result for PPOTrainer_compiler_gym_2f650_00000:\n",
      "  agent_timesteps_total: 5\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5\n",
      "    num_agent_steps_trained: 5\n",
      "    num_env_steps_sampled: 5\n",
      "    num_env_steps_trained: 5\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-28_12-49-06\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 22741b78c628457fb9cd6ba0d13ea2ad\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.375523328781128\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01108794379979372\n",
      "          model: {}\n",
      "          policy_loss: -0.10229093581438065\n",
      "          total_loss: 1.9000144004821777\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.0000877380371094\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 5\n",
      "    num_agent_steps_trained: 5\n",
      "    num_env_steps_sampled: 5\n",
      "    num_env_steps_trained: 5\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 5\n",
      "  num_agent_steps_trained: 5\n",
      "  num_env_steps_sampled: 5\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 5\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 11.550000000000002\n",
      "    ram_util_percent: 50.6\n",
      "  pid: 2264213\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: .nan\n",
      "    episode_media: {}\n",
      "    episode_reward_max: .nan\n",
      "    episode_reward_mean: .nan\n",
      "    episode_reward_min: .nan\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths: []\n",
      "      episode_reward: []\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf: {}\n",
      "  time_since_restore: 3.7372121810913086\n",
      "  time_this_iter_s: 3.7372121810913086\n",
      "  time_total_s: 3.7372121810913086\n",
      "  timers:\n",
      "    learn_throughput: 15.768\n",
      "    learn_time_ms: 317.097\n",
      "    load_throughput: 30615.358\n",
      "    load_time_ms: 0.163\n",
      "    training_iteration_time_ms: 3731.479\n",
      "    update_time_ms: 2.703\n",
      "  timestamp: 1656434946\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f650_00000\n",
      "  warmup_time: 8.35513973236084\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-28 12:49:06 (running for 00:00:16.59)<br>Memory usage on this node: 15.6/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/12 CPUs, 0/0 GPUs, 0.0/10.78 GiB heap, 0.0/5.39 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-28_12-48-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_2f650_00000</td><td>RUNNING </td><td>100.37.253.28:2264213</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.73721</td><td style=\"text-align: right;\">   5</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">               nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m E0628 12:49:09.867813 140386616428096 example_service.py:250] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0628T124858-923072-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  3\n",
      "Result for PPOTrainer_compiler_gym_2f650_00000:\n",
      "  agent_timesteps_total: 15\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15\n",
      "    num_agent_steps_trained: 15\n",
      "    num_env_steps_sampled: 15\n",
      "    num_env_steps_trained: 15\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-28_12-49-13\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2132172938.4211705\n",
      "  episode_reward_mean: -2132172938.4211705\n",
      "  episode_reward_min: -2132172938.4211705\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1\n",
      "  experiment_id: 22741b78c628457fb9cd6ba0d13ea2ad\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3185229301452637\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0009906197665259242\n",
      "          model: {}\n",
      "          policy_loss: 0.0007143571856431663\n",
      "          total_loss: 2.0011203289031982\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.0002076625823975\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 15\n",
      "    num_agent_steps_trained: 15\n",
      "    num_env_steps_sampled: 15\n",
      "    num_env_steps_trained: 15\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 15\n",
      "  num_agent_steps_trained: 15\n",
      "  num_env_steps_sampled: 15\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 15\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 11.5\n",
      "    ram_util_percent: 50.7\n",
      "  pid: 2264213\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.2391121604225852\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 613.0482283505527\n",
      "    mean_inference_ms: 4.644675688310103\n",
      "    mean_raw_obs_processing_ms: 10.105263103138316\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2132172938.4211705\n",
      "    episode_reward_mean: -2132172938.4211705\n",
      "    episode_reward_min: -2132172938.4211705\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2132172938.4211705\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.2391121604225852\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 613.0482283505527\n",
      "      mean_inference_ms: 4.644675688310103\n",
      "      mean_raw_obs_processing_ms: 10.105263103138316\n",
      "  time_since_restore: 10.448305368423462\n",
      "  time_this_iter_s: 3.138362169265747\n",
      "  time_total_s: 10.448305368423462\n",
      "  timers:\n",
      "    learn_throughput: 36.376\n",
      "    learn_time_ms: 137.452\n",
      "    load_throughput: 27437.662\n",
      "    load_time_ms: 0.182\n",
      "    training_iteration_time_ms: 3478.583\n",
      "    update_time_ms: 2.203\n",
      "  timestamp: 1656434953\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15\n",
      "  training_iteration: 3\n",
      "  trial_id: 2f650_00000\n",
      "  warmup_time: 8.35513973236084\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-28 12:49:13 (running for 00:00:23.33)<br>Memory usage on this node: 15.6/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/12 CPUs, 0/0 GPUs, 0.0/10.78 GiB heap, 0.0/5.39 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-28_12-48-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">      reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_2f650_00000</td><td>RUNNING </td><td>100.37.253.28:2264213</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         10.4483</td><td style=\"text-align: right;\">  15</td><td style=\"text-align: right;\">-2.13217e+09</td><td style=\"text-align: right;\">        -2.13217e+09</td><td style=\"text-align: right;\">        -2.13217e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m E0628 12:49:16.290218 140386616428096 example_service.py:250] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0628T124858-923072-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  5\n",
      "Result for PPOTrainer_compiler_gym_2f650_00000:\n",
      "  agent_timesteps_total: 25\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 25\n",
      "    num_agent_steps_trained: 25\n",
      "    num_env_steps_sampled: 25\n",
      "    num_env_steps_trained: 25\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-28_12-49-20\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2121177515.0559127\n",
      "  episode_reward_mean: -2126675226.7385416\n",
      "  episode_reward_min: -2132172938.4211705\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 2\n",
      "  experiment_id: 22741b78c628457fb9cd6ba0d13ea2ad\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3586273193359375\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0075253513641655445\n",
      "          model: {}\n",
      "          policy_loss: -0.07856392115354538\n",
      "          total_loss: 1.9239250421524048\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.0017364025115967\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 25\n",
      "    num_agent_steps_trained: 25\n",
      "    num_env_steps_sampled: 25\n",
      "    num_env_steps_trained: 25\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 25\n",
      "  num_agent_steps_trained: 25\n",
      "  num_env_steps_sampled: 25\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 25\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.666666666666666\n",
      "    ram_util_percent: 50.699999999999996\n",
      "  pid: 2264213\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21922639954141723\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 612.665513377169\n",
      "    mean_inference_ms: 3.7953616220713693\n",
      "    mean_raw_obs_processing_ms: 10.32697277151661\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2121177515.0559127\n",
      "    episode_reward_mean: -2126675226.7385416\n",
      "    episode_reward_min: -2132172938.4211705\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2132172938.4211705\n",
      "      - -2121177515.0559127\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.21922639954141723\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 612.665513377169\n",
      "      mean_inference_ms: 3.7953616220713693\n",
      "      mean_raw_obs_processing_ms: 10.32697277151661\n",
      "  time_since_restore: 17.412482500076294\n",
      "  time_this_iter_s: 3.7406914234161377\n",
      "  time_total_s: 17.412482500076294\n",
      "  timers:\n",
      "    learn_throughput: 49.091\n",
      "    learn_time_ms: 101.852\n",
      "    load_throughput: 26445.801\n",
      "    load_time_ms: 0.189\n",
      "    training_iteration_time_ms: 3478.073\n",
      "    update_time_ms: 2.12\n",
      "  timestamp: 1656434960\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25\n",
      "  training_iteration: 5\n",
      "  trial_id: 2f650_00000\n",
      "  warmup_time: 8.35513973236084\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-28 12:49:20 (running for 00:00:30.36)<br>Memory usage on this node: 15.6/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/12 CPUs, 0/0 GPUs, 0.0/10.78 GiB heap, 0.0/5.39 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-28_12-48-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">      reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_2f650_00000</td><td>RUNNING </td><td>100.37.253.28:2264213</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         17.4125</td><td style=\"text-align: right;\">  25</td><td style=\"text-align: right;\">-2.12668e+09</td><td style=\"text-align: right;\">        -2.12118e+09</td><td style=\"text-align: right;\">        -2.13217e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for k_5587 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for n_5625 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m E0628 12:49:22.892536 140386616428096 example_service.py:250] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0628T124858-923072-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for n_5625 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  8\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  2\n",
      "Result for PPOTrainer_compiler_gym_2f650_00000:\n",
      "  agent_timesteps_total: 35\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 35\n",
      "    num_agent_steps_trained: 35\n",
      "    num_env_steps_sampled: 35\n",
      "    num_env_steps_trained: 35\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-28_12-49-26\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2110369216.9891403\n",
      "  episode_reward_mean: -2121239890.155408\n",
      "  episode_reward_min: -2132172938.4211705\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 3\n",
      "  experiment_id: 22741b78c628457fb9cd6ba0d13ea2ad\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.05000000074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3720885515213013\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.001621950650587678\n",
      "          model: {}\n",
      "          policy_loss: -0.013009237125515938\n",
      "          total_loss: 1.9879306554794312\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.000858783721924\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 35\n",
      "    num_agent_steps_trained: 35\n",
      "    num_env_steps_sampled: 35\n",
      "    num_env_steps_trained: 35\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 35\n",
      "  num_agent_steps_trained: 35\n",
      "  num_env_steps_sampled: 35\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 35\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.05\n",
      "    ram_util_percent: 50.7\n",
      "  pid: 2264213\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20664259746288535\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 614.4207873191491\n",
      "    mean_inference_ms: 3.319298905300394\n",
      "    mean_raw_obs_processing_ms: 10.476983282167986\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2110369216.9891403\n",
      "    episode_reward_mean: -2121239890.155408\n",
      "    episode_reward_min: -2132172938.4211705\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2132172938.4211705\n",
      "      - -2121177515.0559127\n",
      "      - -2110369216.9891403\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.20664259746288535\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 614.4207873191491\n",
      "      mean_inference_ms: 3.319298905300394\n",
      "      mean_raw_obs_processing_ms: 10.476983282167986\n",
      "  time_since_restore: 23.589842557907104\n",
      "  time_this_iter_s: 3.377330780029297\n",
      "  time_total_s: 23.589842557907104\n",
      "  timers:\n",
      "    learn_throughput: 57.47\n",
      "    learn_time_ms: 87.002\n",
      "    load_throughput: 27651.279\n",
      "    load_time_ms: 0.181\n",
      "    training_iteration_time_ms: 3365.517\n",
      "    update_time_ms: 2.054\n",
      "  timestamp: 1656434966\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 35\n",
      "  training_iteration: 7\n",
      "  trial_id: 2f650_00000\n",
      "  warmup_time: 8.35513973236084\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-28 12:49:26 (running for 00:00:36.61)<br>Memory usage on this node: 15.6/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/12 CPUs, 0/0 GPUs, 0.0/10.78 GiB heap, 0.0/5.39 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-28_12-48-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">      reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_2f650_00000</td><td>RUNNING </td><td>100.37.253.28:2264213</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         23.5898</td><td style=\"text-align: right;\">  35</td><td style=\"text-align: right;\">-2.12124e+09</td><td style=\"text-align: right;\">        -2.11037e+09</td><td style=\"text-align: right;\">        -2.13217e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for n_5625 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m E0628 12:49:30.131244 140386616428096 example_service.py:250] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0628T124858-923072-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = swap_down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  2\n",
      "Result for PPOTrainer_compiler_gym_2f650_00000:\n",
      "  agent_timesteps_total: 45\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 45\n",
      "    num_agent_steps_trained: 45\n",
      "    num_env_steps_sampled: 45\n",
      "    num_env_steps_trained: 45\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-28_12-49-33\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2110369216.9891403\n",
      "  episode_reward_mean: -2119953738.3542862\n",
      "  episode_reward_min: -2132172938.4211705\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: 22741b78c628457fb9cd6ba0d13ea2ad\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.012500000186264515\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2965813875198364\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009330833330750465\n",
      "          model: {}\n",
      "          policy_loss: -0.08239029347896576\n",
      "          total_loss: 1.9191844463348389\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2.001458168029785\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 45\n",
      "    num_agent_steps_trained: 45\n",
      "    num_env_steps_sampled: 45\n",
      "    num_env_steps_trained: 45\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 45\n",
      "  num_agent_steps_trained: 45\n",
      "  num_env_steps_sampled: 45\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 45\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 11.559999999999999\n",
      "    ram_util_percent: 50.7\n",
      "  pid: 2264213\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.19599139747445654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 619.853809999417\n",
      "    mean_inference_ms: 3.0015202369787906\n",
      "    mean_raw_obs_processing_ms: 10.559602925348033\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2110369216.9891403\n",
      "    episode_reward_mean: -2119953738.3542862\n",
      "    episode_reward_min: -2132172938.4211705\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2132172938.4211705\n",
      "      - -2121177515.0559127\n",
      "      - -2110369216.9891403\n",
      "      - -2116095282.9509213\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.19599139747445654\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 619.853809999417\n",
      "      mean_inference_ms: 3.0015202369787906\n",
      "      mean_raw_obs_processing_ms: 10.559602925348033\n",
      "  time_since_restore: 30.776724815368652\n",
      "  time_this_iter_s: 3.402735710144043\n",
      "  time_total_s: 30.776724815368652\n",
      "  timers:\n",
      "    learn_throughput: 63.463\n",
      "    learn_time_ms: 78.786\n",
      "    load_throughput: 27318.524\n",
      "    load_time_ms: 0.183\n",
      "    training_iteration_time_ms: 3415.222\n",
      "    update_time_ms: 2.032\n",
      "  timestamp: 1656434973\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45\n",
      "  training_iteration: 9\n",
      "  trial_id: 2f650_00000\n",
      "  warmup_time: 8.35513973236084\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-28 12:49:33 (running for 00:00:43.85)<br>Memory usage on this node: 15.6/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/12 CPUs, 0/0 GPUs, 0.0/10.78 GiB heap, 0.0/5.39 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-28_12-48-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">      reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_2f650_00000</td><td>RUNNING </td><td>100.37.253.28:2264213</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         30.7767</td><td style=\"text-align: right;\">  45</td><td style=\"text-align: right;\">-2.11995e+09</td><td style=\"text-align: right;\">        -2.11037e+09</td><td style=\"text-align: right;\">        -2.13217e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for m_5586 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  3\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for k_5587 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for m_5586 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  4\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = swap_up\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for k_5587 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for m_5586 in 128 : L2  <<<<<< cursor (line 2 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for m_5586 in 128 : L5  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Action = down\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for n_5625 in 128 : L0  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for m_5586 in 128 : L1  <<<<<< cursor (line 1 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m >>> AGENT ITERATION =  6\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m for m_5586 in 128 : L0  <<<<<< cursor (line 0 )\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m  for n_5625 in 128 : L1  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   for k_5587 in 128 : L2  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %2[m_5586, k_5587, n_5625] <- multiply(%0, %1)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m    %3[m_5586, n_5625] <- add(%2)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m   %4[m_5586, n_5625] <- write(%3)  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "Result for PPOTrainer_compiler_gym_2f650_00000:\n",
      "  agent_timesteps_total: 50\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 50\n",
      "    num_agent_steps_trained: 50\n",
      "    num_env_steps_sampled: 50\n",
      "    num_env_steps_trained: 50\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-28_12-49-37\n",
      "  done: true\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2110369216.9891403\n",
      "  episode_reward_mean: -2120558380.904883\n",
      "  episode_reward_min: -2132172938.4211705\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 5\n",
      "  experiment_id: 22741b78c628457fb9cd6ba0d13ea2ad\n",
      "  hostname: codah\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.012500000186264515\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.294608473777771\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.004307971335947514\n",
      "          model: {}\n",
      "          policy_loss: -0.04504469409584999\n",
      "          total_loss: 0.6478586792945862\n",
      "          vf_explained_var: 0.22915607690811157\n",
      "          vf_loss: 0.6928494572639465\n",
      "        num_agent_steps_trained: 5.0\n",
      "    num_agent_steps_sampled: 50\n",
      "    num_agent_steps_trained: 50\n",
      "    num_env_steps_sampled: 50\n",
      "    num_env_steps_trained: 50\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 100.37.253.28\n",
      "  num_agent_steps_sampled: 50\n",
      "  num_agent_steps_trained: 50\n",
      "  num_env_steps_sampled: 50\n",
      "  num_env_steps_sampled_this_iter: 5\n",
      "  num_env_steps_trained: 50\n",
      "  num_env_steps_trained_this_iter: 5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.16\n",
      "    ram_util_percent: 50.7\n",
      "  pid: 2264213\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18824660589939138\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 625.92290822005\n",
      "    mean_inference_ms: 2.770405021884752\n",
      "    mean_raw_obs_processing_ms: 10.611652576963188\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 10.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2110369216.9891403\n",
      "    episode_reward_mean: -2120558380.904883\n",
      "    episode_reward_min: -2132172938.4211705\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      episode_reward:\n",
      "      - -2132172938.4211705\n",
      "      - -2121177515.0559127\n",
      "      - -2110369216.9891403\n",
      "      - -2116095282.9509213\n",
      "      - -2122976951.10727\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.18824660589939138\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 625.92290822005\n",
      "      mean_inference_ms: 2.770405021884752\n",
      "      mean_raw_obs_processing_ms: 10.611652576963188\n",
      "  time_since_restore: 34.69034290313721\n",
      "  time_this_iter_s: 3.9136180877685547\n",
      "  time_total_s: 34.69034290313721\n",
      "  timers:\n",
      "    learn_throughput: 65.913\n",
      "    learn_time_ms: 75.858\n",
      "    load_throughput: 27438.859\n",
      "    load_time_ms: 0.182\n",
      "    training_iteration_time_ms: 3464.631\n",
      "    update_time_ms: 2.03\n",
      "  timestamp: 1656434977\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 50\n",
      "  training_iteration: 10\n",
      "  trial_id: 2f650_00000\n",
      "  warmup_time: 8.35513973236084\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m E0628 12:49:37.508636 140386616428096 example_service.py:250] CRITICAL - \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m Working_dir = /dev/shm/compiler_gym_dejang/s/0628T124858-923072-6f35\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2264258)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-28 12:49:37 (running for 00:00:47.87)<br>Memory usage on this node: 15.6/30.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/10.78 GiB heap, 0.0/5.39 GiB objects<br>Result logdir: /home/dejang/ray_results/PPOTrainer_2022-06-28_12-48-49<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                         </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">      reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPOTrainer_compiler_gym_2f650_00000</td><td>TERMINATED</td><td>100.37.253.28:2264213</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         34.6903</td><td style=\"text-align: right;\">  50</td><td style=\"text-align: right;\">-2.12056e+09</td><td style=\"text-align: right;\">        -2.11037e+09</td><td style=\"text-align: right;\">        -2.13217e+09</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 12:49:38,808\tINFO tune.py:747 -- Total run time: 48.95 seconds (47.83 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    PPOTrainer,\n",
    "    checkpoint_at_end=True,\n",
    "    stop={\n",
    "        \"episodes_total\": 5,\n",
    "    },\n",
    "    config={\n",
    "        \"seed\": 0xCC,\n",
    "        \"num_workers\": 1,\n",
    "        # Specify the environment to use, where \"compiler_gym\" is the name we \n",
    "        # passed to tune.register_env().\n",
    "        \"env\": \"compiler_gym\",\n",
    "        # Reduce the size of the batch/trajectory lengths to match our short \n",
    "        # training run.\n",
    "        \"rollout_fragment_length\": 5,\n",
    "        \"train_batch_size\": 5,\n",
    "        \"sgd_minibatch_size\": 5,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = analysis.get_best_checkpoint(\n",
    "    metric=\"episode_reward_mean\",\n",
    "    mode=\"max\",\n",
    "    trial=analysis.trials[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>num_agent_steps_sampled</th>\n",
       "      <th>num_agent_steps_trained</th>\n",
       "      <th>num_env_steps_sampled</th>\n",
       "      <th>num_env_steps_trained</th>\n",
       "      <th>...</th>\n",
       "      <th>info/learner/default_policy/learner_stats/kl</th>\n",
       "      <th>info/learner/default_policy/learner_stats/entropy</th>\n",
       "      <th>info/learner/default_policy/learner_stats/entropy_coeff</th>\n",
       "      <th>config/env</th>\n",
       "      <th>config/num_workers</th>\n",
       "      <th>config/rollout_fragment_length</th>\n",
       "      <th>config/seed</th>\n",
       "      <th>config/sgd_minibatch_size</th>\n",
       "      <th>config/train_batch_size</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.110369e+09</td>\n",
       "      <td>-2.132173e+09</td>\n",
       "      <td>-2.120558e+09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>1.294609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>compiler_gym</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>/home/dejang/ray_results/PPOTrainer_2022-06-28...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0       -2.110369e+09       -2.132173e+09        -2.120558e+09   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_healthy_workers  \\\n",
       "0              10.0                   1                    1   \n",
       "\n",
       "   num_agent_steps_sampled  num_agent_steps_trained  num_env_steps_sampled  \\\n",
       "0                       50                       50                     50   \n",
       "\n",
       "   num_env_steps_trained  ...  info/learner/default_policy/learner_stats/kl  \\\n",
       "0                     50  ...                                      0.004308   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/entropy  \\\n",
       "0                                           1.294609   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/entropy_coeff    config/env  \\\n",
       "0                                                0.0        compiler_gym   \n",
       "\n",
       "   config/num_workers  config/rollout_fragment_length  config/seed  \\\n",
       "0                   1                               5          204   \n",
       "\n",
       "  config/sgd_minibatch_size config/train_batch_size  \\\n",
       "0                         5                       5   \n",
       "\n",
       "                                              logdir  \n",
       "0  /home/dejang/ray_results/PPOTrainer_2022-06-28...  \n",
       "\n",
       "[1 rows x 72 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PPOTrainer_compiler_gym_2f650_00000, ray.tune.trial.Trial)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = analysis.get_best_trial(metric=\"episode_reward_mean\", mode=\"max\")\n",
    "trial, type(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episodes_total': 5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.stopping_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode_reward_max': {'max': -2110369216.9891403,\n",
       "  'min': -2132172938.4211705,\n",
       "  'avg': nan,\n",
       "  'last': -2110369216.9891403,\n",
       "  'last-5-avg': -2110369216.9891403,\n",
       "  'last-10-avg': nan},\n",
       " 'episode_reward_min': {'max': -2132172938.4211705,\n",
       "  'min': -2132172938.4211705,\n",
       "  'avg': nan,\n",
       "  'last': -2132172938.4211705,\n",
       "  'last-5-avg': -2132172938.4211705,\n",
       "  'last-10-avg': nan},\n",
       " 'episode_reward_mean': {'max': -2119953738.3542862,\n",
       "  'min': -2132172938.4211705,\n",
       "  'avg': nan,\n",
       "  'last': -2120558380.904883,\n",
       "  'last-5-avg': -2120589127.5848541,\n",
       "  'last-10-avg': nan},\n",
       " 'episode_len_mean': {'max': 10.0,\n",
       "  'min': 10.0,\n",
       "  'avg': nan,\n",
       "  'last': 10.0,\n",
       "  'last-5-avg': 10.0,\n",
       "  'last-10-avg': nan},\n",
       " 'episodes_this_iter': {'max': 1,\n",
       "  'min': 0,\n",
       "  'avg': 0.5,\n",
       "  'last': 1,\n",
       "  'last-5-avg': 0.6,\n",
       "  'last-10-avg': 0.5},\n",
       " 'num_healthy_workers': {'max': 1,\n",
       "  'min': 1,\n",
       "  'avg': 1.0,\n",
       "  'last': 1,\n",
       "  'last-5-avg': 1.0,\n",
       "  'last-10-avg': 1.0},\n",
       " 'num_agent_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'num_agent_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'num_env_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'num_env_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'num_env_steps_sampled_this_iter': {'max': 5,\n",
       "  'min': 5,\n",
       "  'avg': 5.0,\n",
       "  'last': 5,\n",
       "  'last-5-avg': 5.0,\n",
       "  'last-10-avg': 5.0},\n",
       " 'num_env_steps_trained_this_iter': {'max': 5,\n",
       "  'min': 5,\n",
       "  'avg': 5.0,\n",
       "  'last': 5,\n",
       "  'last-5-avg': 5.0,\n",
       "  'last-10-avg': 5.0},\n",
       " 'timesteps_total': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'agent_timesteps_total': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'done': {'max': True,\n",
       "  'min': False,\n",
       "  'avg': 0.1,\n",
       "  'last': True,\n",
       "  'last-5-avg': 0.2,\n",
       "  'last-10-avg': 0.1},\n",
       " 'episodes_total': {'max': 5,\n",
       "  'min': 0,\n",
       "  'avg': 2.5,\n",
       "  'last': 5,\n",
       "  'last-5-avg': 3.8,\n",
       "  'last-10-avg': 2.5},\n",
       " 'training_iteration': {'max': 10,\n",
       "  'min': 1,\n",
       "  'avg': 5.5,\n",
       "  'last': 10,\n",
       "  'last-5-avg': 8.0,\n",
       "  'last-10-avg': 5.5},\n",
       " 'time_this_iter_s': {'max': 3.9136180877685547,\n",
       "  'min': 2.8000292778015137,\n",
       "  'avg': 3.469034290313721,\n",
       "  'last': 3.9136180877685547,\n",
       "  'last-5-avg': 3.455572080612183,\n",
       "  'last-10-avg': 3.469034290313721},\n",
       " 'time_total_s': {'max': 34.69034290313721,\n",
       "  'min': 3.7372121810913086,\n",
       "  'avg': 18.922314548492434,\n",
       "  'last': 34.69034290313721,\n",
       "  'last-5-avg': 27.328682231903077,\n",
       "  'last-10-avg': 18.92231454849243},\n",
       " 'time_since_restore': {'max': 34.69034290313721,\n",
       "  'min': 3.7372121810913086,\n",
       "  'avg': 18.922314548492434,\n",
       "  'last': 34.69034290313721,\n",
       "  'last-5-avg': 27.328682231903077,\n",
       "  'last-10-avg': 18.92231454849243},\n",
       " 'timesteps_since_restore': {'max': 0,\n",
       "  'min': 0,\n",
       "  'avg': 0.0,\n",
       "  'last': 0,\n",
       "  'last-5-avg': 0.0,\n",
       "  'last-10-avg': 0.0},\n",
       " 'iterations_since_restore': {'max': 10,\n",
       "  'min': 1,\n",
       "  'avg': 5.5,\n",
       "  'last': 10,\n",
       "  'last-5-avg': 8.0,\n",
       "  'last-10-avg': 5.5},\n",
       " 'warmup_time': {'max': 8.35513973236084,\n",
       "  'min': 8.35513973236084,\n",
       "  'avg': 8.35513973236084,\n",
       "  'last': 8.35513973236084,\n",
       "  'last-5-avg': 8.35513973236084,\n",
       "  'last-10-avg': 8.35513973236084},\n",
       " 'info/num_env_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'info/num_env_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'info/num_agent_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'info/num_agent_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'sampler_results/episode_reward_max': {'max': -2110369216.9891403,\n",
       "  'min': -2132172938.4211705,\n",
       "  'avg': nan,\n",
       "  'last': -2110369216.9891403,\n",
       "  'last-5-avg': -2110369216.9891403,\n",
       "  'last-10-avg': nan},\n",
       " 'sampler_results/episode_reward_min': {'max': -2132172938.4211705,\n",
       "  'min': -2132172938.4211705,\n",
       "  'avg': nan,\n",
       "  'last': -2132172938.4211705,\n",
       "  'last-5-avg': -2132172938.4211705,\n",
       "  'last-10-avg': nan},\n",
       " 'sampler_results/episode_reward_mean': {'max': -2119953738.3542862,\n",
       "  'min': -2132172938.4211705,\n",
       "  'avg': nan,\n",
       "  'last': -2120558380.904883,\n",
       "  'last-5-avg': -2120589127.5848541,\n",
       "  'last-10-avg': nan},\n",
       " 'sampler_results/episode_len_mean': {'max': 10.0,\n",
       "  'min': 10.0,\n",
       "  'avg': nan,\n",
       "  'last': 10.0,\n",
       "  'last-5-avg': 10.0,\n",
       "  'last-10-avg': nan},\n",
       " 'sampler_results/episodes_this_iter': {'max': 1,\n",
       "  'min': 0,\n",
       "  'avg': 0.5,\n",
       "  'last': 1,\n",
       "  'last-5-avg': 0.6,\n",
       "  'last-10-avg': 0.5},\n",
       " 'timers/training_iteration_time_ms': {'max': 3731.479,\n",
       "  'min': 3364.245,\n",
       "  'avg': 3477.8273000000004,\n",
       "  'last': 3464.631,\n",
       "  'last-5-avg': 3405.3918,\n",
       "  'last-10-avg': 3477.8273},\n",
       " 'timers/load_time_ms': {'max': 0.189,\n",
       "  'min': 0.163,\n",
       "  'avg': 0.1814,\n",
       "  'last': 0.182,\n",
       "  'last-5-avg': 0.18380000000000002,\n",
       "  'last-10-avg': 0.1814},\n",
       " 'timers/load_throughput': {'max': 30615.358,\n",
       "  'min': 26445.801,\n",
       "  'avg': 27586.249200000006,\n",
       "  'last': 27438.859,\n",
       "  'last-5-avg': 27196.441600000002,\n",
       "  'last-10-avg': 27586.249200000002},\n",
       " 'timers/learn_time_ms': {'max': 317.097,\n",
       "  'min': 75.858,\n",
       "  'avg': 127.3196,\n",
       "  'last': 75.858,\n",
       "  'last-5-avg': 83.546,\n",
       "  'last-10-avg': 127.3196},\n",
       " 'timers/learn_throughput': {'max': 65.913,\n",
       "  'min': 15.768,\n",
       "  'avg': 47.24679999999999,\n",
       "  'last': 65.913,\n",
       "  'last-5-avg': 60.181,\n",
       "  'last-10-avg': 47.2468},\n",
       " 'timers/update_time_ms': {'max': 2.703,\n",
       "  'min': 2.03,\n",
       "  'avg': 2.1866,\n",
       "  'last': 2.03,\n",
       "  'last-5-avg': 2.0614,\n",
       "  'last-10-avg': 2.1866000000000003},\n",
       " 'counters/num_env_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'counters/num_env_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'counters/num_agent_steps_sampled': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'counters/num_agent_steps_trained': {'max': 50,\n",
       "  'min': 5,\n",
       "  'avg': 27.5,\n",
       "  'last': 50,\n",
       "  'last-5-avg': 40.0,\n",
       "  'last-10-avg': 27.5},\n",
       " 'perf/cpu_util_percent': {'max': 12.666666666666666,\n",
       "  'min': 11.149999999999999,\n",
       "  'avg': 11.839833333333331,\n",
       "  'last': 12.16,\n",
       "  'last-5-avg': 11.787333333333333,\n",
       "  'last-10-avg': 11.839833333333333},\n",
       " 'perf/ram_util_percent': {'max': 50.7,\n",
       "  'min': 50.6,\n",
       "  'avg': 50.68799999999999,\n",
       "  'last': 50.7,\n",
       "  'last-5-avg': 50.7,\n",
       "  'last-10-avg': 50.687999999999995},\n",
       " 'info/learner/default_policy/num_agent_steps_trained': {'max': 5.0,\n",
       "  'min': 5.0,\n",
       "  'avg': 5.0,\n",
       "  'last': 5.0,\n",
       "  'last-5-avg': 5.0,\n",
       "  'last-10-avg': 5.0},\n",
       " 'info/learner/default_policy/learner_stats/cur_kl_coeff': {'max': 0.20000000298023224,\n",
       "  'min': 0.012500000186264515,\n",
       "  'avg': 0.10000000149011612,\n",
       "  'last': 0.012500000186264515,\n",
       "  'last-5-avg': 0.04000000059604645,\n",
       "  'last-10-avg': 0.10000000149011612},\n",
       " 'info/learner/default_policy/learner_stats/cur_lr': {'max': 4.999999873689376e-05,\n",
       "  'min': 4.999999873689376e-05,\n",
       "  'avg': 4.999999873689376e-05,\n",
       "  'last': 4.999999873689376e-05,\n",
       "  'last-5-avg': 4.999999873689376e-05,\n",
       "  'last-10-avg': 4.999999873689376e-05},\n",
       " 'info/learner/default_policy/learner_stats/total_loss': {'max': 9.984122,\n",
       "  'min': -0.06440187,\n",
       "  'avg': 2.0240378515794872,\n",
       "  'last': 0.6478587,\n",
       "  'last-5-avg': 2.9026050459593535,\n",
       "  'last-10-avg': 2.0240378515794872},\n",
       " 'info/learner/default_policy/learner_stats/policy_loss': {'max': 0.0007143572,\n",
       "  'min': -0.102290936,\n",
       "  'avg': -0.046577523351879785,\n",
       "  'last': -0.045044694,\n",
       "  'last-5-avg': -0.03695592880249023,\n",
       "  'last-10-avg': -0.04657752335187979},\n",
       " 'info/learner/default_policy/learner_stats/vf_loss': {'max': 10.0,\n",
       "  'min': 0.00024188987,\n",
       "  'avg': 2.069988054285932,\n",
       "  'last': 0.69284946,\n",
       "  'last-5-avg': 2.939456950919703,\n",
       "  'last-10-avg': 2.0699880542859317},\n",
       " 'info/learner/default_policy/learner_stats/vf_explained_var': {'max': 0.22915608,\n",
       "  'min': 0.0,\n",
       "  'avg': 0.025936203612945977,\n",
       "  'last': 0.22915608,\n",
       "  'last-5-avg': 0.0497823238838464,\n",
       "  'last-10-avg': 0.025936203612945973},\n",
       " 'info/learner/default_policy/learner_stats/kl': {'max': 0.011743461,\n",
       "  'min': 0.0009906198,\n",
       "  'avg': 0.005961979064159096,\n",
       "  'last': 0.0043079713,\n",
       "  'last-5-avg': 0.004244202165864408,\n",
       "  'last-10-avg': 0.005961979064159096},\n",
       " 'info/learner/default_policy/learner_stats/entropy': {'max': 1.3790616,\n",
       "  'min': 1.2946085,\n",
       "  'avg': 1.341549742221832,\n",
       "  'last': 1.2946085,\n",
       "  'last-5-avg': 1.3371774911880494,\n",
       "  'last-10-avg': 1.3415497422218323},\n",
       " 'info/learner/default_policy/learner_stats/entropy_coeff': {'max': 0.0,\n",
       "  'min': 0.0,\n",
       "  'avg': 0.0,\n",
       "  'last': 0.0,\n",
       "  'last-5-avg': 0.0,\n",
       "  'last-10-avg': 0.0},\n",
       " 'sampler_perf/mean_raw_obs_processing_ms': {'max': 10.611652576963188,\n",
       "  'min': 10.105263103138316,\n",
       "  'avg': 10.365455984444338,\n",
       "  'last': 10.611652576963188,\n",
       "  'last-5-avg': 10.536964998399045,\n",
       "  'last-10-avg': 10.394366304589454},\n",
       " 'sampler_perf/mean_inference_ms': {'max': 4.644675688310103,\n",
       "  'min': 2.770405021884752,\n",
       "  'avg': 3.6936793615516166,\n",
       "  'last': 2.770405021884752,\n",
       "  'last-5-avg': 3.082408661288624,\n",
       "  'last-10-avg': 3.588013103022896},\n",
       " 'sampler_perf/mean_action_processing_ms': {'max': 0.2391121604225852,\n",
       "  'min': 0.18824660589939138,\n",
       "  'avg': 0.21493038761246647,\n",
       "  'last': 0.18824660589939138,\n",
       "  'last-5-avg': 0.19870291915481503,\n",
       "  'last-10-avg': 0.21224352396689777},\n",
       " 'sampler_perf/mean_env_wait_ms': {'max': 625.92290822005,\n",
       "  'min': 612.665513377169,\n",
       "  'avg': 615.8947814663177,\n",
       "  'last': 625.92290822005,\n",
       "  'last-5-avg': 618.8944205714364,\n",
       "  'last-10-avg': 616.2110651458472},\n",
       " 'sampler_perf/mean_env_render_ms': {'max': 0.0,\n",
       "  'min': 0.0,\n",
       "  'avg': 0.0,\n",
       "  'last': 0.0,\n",
       "  'last-5-avg': 0.0,\n",
       "  'last-10-avg': 0.0},\n",
       " 'sampler_results/sampler_perf/mean_raw_obs_processing_ms': {'max': 10.611652576963188,\n",
       "  'min': 10.105263103138316,\n",
       "  'avg': 10.365455984444338,\n",
       "  'last': 10.611652576963188,\n",
       "  'last-5-avg': 10.536964998399045,\n",
       "  'last-10-avg': 10.394366304589454},\n",
       " 'sampler_results/sampler_perf/mean_inference_ms': {'max': 4.644675688310103,\n",
       "  'min': 2.770405021884752,\n",
       "  'avg': 3.6936793615516166,\n",
       "  'last': 2.770405021884752,\n",
       "  'last-5-avg': 3.082408661288624,\n",
       "  'last-10-avg': 3.588013103022896},\n",
       " 'sampler_results/sampler_perf/mean_action_processing_ms': {'max': 0.2391121604225852,\n",
       "  'min': 0.18824660589939138,\n",
       "  'avg': 0.21493038761246647,\n",
       "  'last': 0.18824660589939138,\n",
       "  'last-5-avg': 0.19870291915481503,\n",
       "  'last-10-avg': 0.21224352396689777},\n",
       " 'sampler_results/sampler_perf/mean_env_wait_ms': {'max': 625.92290822005,\n",
       "  'min': 612.665513377169,\n",
       "  'avg': 615.8947814663177,\n",
       "  'last': 625.92290822005,\n",
       "  'last-5-avg': 618.8944205714364,\n",
       "  'last-10-avg': 616.2110651458472},\n",
       " 'sampler_results/sampler_perf/mean_env_render_ms': {'max': 0.0,\n",
       "  'min': 0.0,\n",
       "  'avg': 0.0,\n",
       "  'last': 0.0,\n",
       "  'last-5-avg': 0.0,\n",
       "  'last-10-avg': 0.0}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.metric_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.restore(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_agent_on_benchmarks(benchmarks):\n",
    "#     \"\"\"Run agent on a list of benchmarks and return a list of cumulative rewards.\"\"\"\n",
    "#     with make_env() as env:\n",
    "#         rewards = []\n",
    "#         for i, benchmark in enumerate(benchmarks, start=1):\n",
    "#             observation, done = env.reset(benchmark=benchmark), False\n",
    "#             while not done:\n",
    "#                 action = agent.compute_single_action(observation)\n",
    "#                 observation, _, done, _ = env.step(int(action))\n",
    "#             rewards.append(env.episode_reward)\n",
    "            \n",
    "#             print(f\"[{i}/{len(benchmarks)}] \")\n",
    "\n",
    "#     return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_rewards = run_agent_on_benchmarks(train_benchmarks)\n",
    "# test_rewards = run_agent_on_benchmarks(test_benchmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "# axs[0].title.set_text('Train rewards')\n",
    "# axs[0].plot(train_rewards, color=\"red\")\n",
    "# axs[0].plot(np.zeros_like(train_rewards), color=\"blue\")\n",
    "\n",
    "# axs[1].title.set_text('Test rewards')\n",
    "# axs[1].plot(test_rewards, color=\"green\")\n",
    "# axs[1].plot(np.zeros_like(test_rewards), color=\"blue\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e804d18dc74ce1dc9e76e68b7cf0aefb2bc0afdfbb2c1892ec3bac3a66589459"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('compiler_gym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
