{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import loop_tool as lt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "# import time\n",
    "from IPython import display\n",
    "from ipywidgets import Output\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pdb\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ir</th>\n",
       "      <th>loops_tensor</th>\n",
       "      <th>program_tensor</th>\n",
       "      <th>gflops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...</td>\n",
       "      <td>[[tensor(1), tensor(0), tensor(1), tensor(1), ...</td>\n",
       "      <td>[tensor(14196.), tensor(0.), tensor(0.), tenso...</td>\n",
       "      <td>32.809471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...</td>\n",
       "      <td>[[tensor(1), tensor(0), tensor(1), tensor(0), ...</td>\n",
       "      <td>[tensor(14196.), tensor(0.), tensor(0.), tenso...</td>\n",
       "      <td>42.649964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...</td>\n",
       "      <td>[[tensor(1), tensor(0), tensor(1), tensor(0), ...</td>\n",
       "      <td>[tensor(14196.), tensor(0.), tensor(0.), tenso...</td>\n",
       "      <td>32.809471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...</td>\n",
       "      <td>[[tensor(1), tensor(0), tensor(1), tensor(0), ...</td>\n",
       "      <td>[tensor(14196.), tensor(0.), tensor(0.), tenso...</td>\n",
       "      <td>32.827548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...</td>\n",
       "      <td>[[tensor(1), tensor(0), tensor(1), tensor(0), ...</td>\n",
       "      <td>[tensor(14196.), tensor(0.), tensor(0.), tenso...</td>\n",
       "      <td>60.92229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ir  \\\n",
       "0  v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...   \n",
       "1  v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...   \n",
       "2  v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...   \n",
       "3  v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...   \n",
       "4  v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...   \n",
       "\n",
       "                                        loops_tensor  \\\n",
       "0  [[tensor(1), tensor(0), tensor(1), tensor(1), ...   \n",
       "1  [[tensor(1), tensor(0), tensor(1), tensor(0), ...   \n",
       "2  [[tensor(1), tensor(0), tensor(1), tensor(0), ...   \n",
       "3  [[tensor(1), tensor(0), tensor(1), tensor(0), ...   \n",
       "4  [[tensor(1), tensor(0), tensor(1), tensor(0), ...   \n",
       "\n",
       "                                      program_tensor     gflops  \n",
       "0  [tensor(14196.), tensor(0.), tensor(0.), tenso...  32.809471  \n",
       "1  [tensor(14196.), tensor(0.), tensor(0.), tenso...  42.649964  \n",
       "2  [tensor(14196.), tensor(0.), tensor(0.), tenso...  32.809471  \n",
       "3  [tensor(14196.), tensor(0.), tensor(0.), tenso...  32.827548  \n",
       "4  [tensor(14196.), tensor(0.), tensor(0.), tenso...   60.92229  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"datasets/tensor_dataset.pkl\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoopToolDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "    ):\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return torch.flatten(self.df['program_tensor'].iloc[0].float()).to(device), torch.tensor(self.df['gflops'].iloc[i]).float().to(device)\n",
    "\n",
    "    def __len__(self):    \n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_tool_dataset = LoopToolDataset(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset training validation = 15840, 3960\n"
     ]
    }
   ],
   "source": [
    "test_size = len(loop_tool_dataset.df) // 5\n",
    "train_size = len(loop_tool_dataset.df) - test_size\n",
    "\n",
    "print(f'Dataset training validation = {train_size}, {test_size}')\n",
    "train_set, test_set = torch.utils.data.random_split(loop_tool_dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 10\n",
    "trainLoad = DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
    "testLoad = DataLoader(test_set,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallNet(nn.Module):\n",
    "    def __init__(self, in_size, out_size, hidden_size, dropout=0):\n",
    "        super(SmallNet,self).__init__()\n",
    "        self.l1 = nn.Linear(in_size,hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.l7 = nn.Linear(hidden_size,out_size)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = F.leaky_relu(self.l3(x))\n",
    "        x = self.l7(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmallNet(\n",
       "  (l1): Linear(in_features=32, out_features=516, bias=True)\n",
       "  (l2): Linear(in_features=516, out_features=516, bias=True)\n",
       "  (l3): Linear(in_features=516, out_features=516, bias=True)\n",
       "  (l7): Linear(in_features=516, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"model_weights.pt\"\n",
    "model = SmallNet(in_size=len(torch.flatten(df['program_tensor'].iloc[0])), out_size=1, hidden_size=516).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [18:33<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "num_epochs = 1000\n",
    "test_every = 10\n",
    "\n",
    "out = Output()\n",
    "display.display(out)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):    \n",
    "    for state, cost in trainLoad:\n",
    "        train_losses_batch = []\n",
    "        \n",
    "        for state, cost in zip(state, cost):\n",
    "            # print(state)\n",
    "            # break\n",
    "            pred_cost = model(state)[0]\n",
    "            train_loss = criterion(pred_cost, cost)\n",
    "            train_losses_batch.append(train_loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "        if epoch % test_every == 0:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                test_losses_batch = []\n",
    "                for state, cost in testLoad:\n",
    "                    for state, cost in zip(state, cost):\n",
    "\n",
    "                        pred_cost = model(state)[0]\n",
    "                        test_loss = criterion(pred_cost, cost )\n",
    "                        test_losses_batch.append(test_loss.item())\n",
    "\n",
    "            train_losses.append(np.mean(train_losses_batch))\n",
    "            test_losses.append(np.mean(test_losses_batch))\n",
    "            # torch.save(model.state_dict(), model_path)\n",
    "\n",
    "            with out:\n",
    "                display.clear_output(wait=True)\n",
    "                plt.title('Loss (blue-train, red-test)')\n",
    "                plt.plot(train_losses, color='blue')\n",
    "                plt.plot(test_losses, color='red')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "    break\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmallNet(\n",
       "  (l1): Linear(in_features=32, out_features=516, bias=True)\n",
       "  (l2): Linear(in_features=516, out_features=516, bias=True)\n",
       "  (l3): Linear(in_features=516, out_features=516, bias=True)\n",
       "  (l7): Linear(in_features=516, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ir</th>\n",
       "      <th>loops_tensor</th>\n",
       "      <th>program_tensor</th>\n",
       "      <th>gflops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...</td>\n",
       "      <td>[[tensor(1), tensor(0), tensor(1), tensor(1), ...</td>\n",
       "      <td>[tensor(14196.), tensor(0.), tensor(0.), tenso...</td>\n",
       "      <td>32.809471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...</td>\n",
       "      <td>[[tensor(1), tensor(0), tensor(1), tensor(0), ...</td>\n",
       "      <td>[tensor(14196.), tensor(0.), tensor(0.), tenso...</td>\n",
       "      <td>42.649964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...</td>\n",
       "      <td>[[tensor(1), tensor(0), tensor(1), tensor(0), ...</td>\n",
       "      <td>[tensor(14196.), tensor(0.), tensor(0.), tenso...</td>\n",
       "      <td>32.809471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...</td>\n",
       "      <td>[[tensor(1), tensor(0), tensor(1), tensor(0), ...</td>\n",
       "      <td>[tensor(14196.), tensor(0.), tensor(0.), tenso...</td>\n",
       "      <td>32.827548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...</td>\n",
       "      <td>[[tensor(1), tensor(0), tensor(1), tensor(0), ...</td>\n",
       "      <td>[tensor(14196.), tensor(0.), tensor(0.), tenso...</td>\n",
       "      <td>60.92229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ir  \\\n",
       "0  v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...   \n",
       "1  v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...   \n",
       "2  v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...   \n",
       "3  v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...   \n",
       "4  v:m_6543\\nv:k_6545\\nv:n_6544\\nn:2::0,1,:::0:::...   \n",
       "\n",
       "                                        loops_tensor  \\\n",
       "0  [[tensor(1), tensor(0), tensor(1), tensor(1), ...   \n",
       "1  [[tensor(1), tensor(0), tensor(1), tensor(0), ...   \n",
       "2  [[tensor(1), tensor(0), tensor(1), tensor(0), ...   \n",
       "3  [[tensor(1), tensor(0), tensor(1), tensor(0), ...   \n",
       "4  [[tensor(1), tensor(0), tensor(1), tensor(0), ...   \n",
       "\n",
       "                                      program_tensor     gflops  \n",
       "0  [tensor(14196.), tensor(0.), tensor(0.), tenso...  32.809471  \n",
       "1  [tensor(14196.), tensor(0.), tensor(0.), tenso...  42.649964  \n",
       "2  [tensor(14196.), tensor(0.), tensor(0.), tenso...  32.809471  \n",
       "3  [tensor(14196.), tensor(0.), tensor(0.), tenso...  32.827548  \n",
       "4  [tensor(14196.), tensor(0.), tensor(0.), tenso...   60.92229  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted = 699406.5, label = 32.809471365638764\n",
      "predicted = 699406.5, label = 42.64996420901933\n",
      "predicted = 699406.5, label = 32.809471365638764\n",
      "predicted = 699406.5, label = 32.82754820936639\n",
      "predicted = 699406.5, label = 60.922290388548056\n",
      "predicted = -463665.53125, label = 60.922290388548056\n",
      "predicted = -463665.53125, label = 32.809471365638764\n",
      "predicted = -463665.53125, label = 32.82754820936639\n",
      "predicted = -463665.53125, label = 60.922290388548056\n",
      "predicted = -463665.53125, label = 32.809471365638764\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'predicted = {model(df[\"program_tensor\"].iloc[i].float())[0]}, label = {df[\"gflops\"].iloc[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e804d18dc74ce1dc9e76e68b7cf0aefb2bc0afdfbb2c1892ec3bac3a66589459"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('compiler_gym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
